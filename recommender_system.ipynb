{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Recommendation System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports + notebook settings (keep all imports in one place)\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise import BaselineOnly, KNNBaseline, SVD\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "\n",
    "# Optional: tighten markdown spacing (kept with imports/settings)\n",
    "from IPython.display import HTML\n",
    "HTML(r'''\n",
    "<style>\n",
    ".rendered_html p { margin: 0.35em 0; }\n",
    ".rendered_html ul { margin: 0.35em 0 0.35em 1.2em; }\n",
    ".rendered_html li { margin: 0.15em 0; }\n",
    "</style>\n",
    "''')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Paths (assumes this notebook lives in /notebooks and data is in data/)\n",
    "DATA_DIR = Path(\"data/\")\n",
    "\n",
    "# Where to save figures (repo-friendly)\n",
    "FIG_DIR = Path(\"../reports/figures\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stakeholder:** A movie streaming platform’s product + personalization team.\n",
    "\n",
    "**Real-world problem:** Users face choice overload; if they can’t quickly find movies they enjoy, engagement drops and churn risk increases.\n",
    "\n",
    "**Project goal:** Build a recommendation system that predicts how a user would rate unseen movies and returns Top-5 personalized recommendations.\n",
    "\n",
    "**How stakeholders would use it:**\n",
    "- Populate a “Recommended for You” row on the homepage\n",
    "- Improve email/push recommendations\n",
    "- Support content discovery and retention efforts\n",
    "\n",
    "**Success criteria:**\n",
    "- Low prediction error (RMSE/MAE) on held-out ratings\n",
    "- Recommendations that are plausible and relevant for sample users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the MovieLens “latest small” dataset (ml-latest-small) from GroupLens. It contains 100,836 ratings and 3,683 tag applications across 9,742 movies from 610 users. Ratings use a 0.5–5.0 scale. These explicit ratings are well-suited to collaborative filtering. \n",
    "\n",
    "**Limitations that matter for this project:**\n",
    "- The user–movie matrix is sparse (most users rate only a small fraction of movies)\n",
    "- Cold start exists for brand-new users and new movies\n",
    "- No user demographics are included\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MovieLens data files\n",
    "ratings = pd.read_csv(DATA_DIR / \"ratings.csv\")\n",
    "movies  = pd.read_csv(DATA_DIR / \"movies.csv\")\n",
    "links   = pd.read_csv(DATA_DIR / \"links.csv\")\n",
    "tags    = pd.read_csv(DATA_DIR / \"tags.csv\")\n",
    "\n",
    "ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings shape: (100836, 4)\n",
      "movies shape: (9742, 3)\n",
      "tags shape: (3683, 4)\n",
      "Unique users: 610\n",
      "Unique movies rated: 9724\n",
      "Rating scale: 0.5 to 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    100836.000000\n",
       "mean          3.501557\n",
       "std           1.042529\n",
       "min           0.500000\n",
       "25%           3.000000\n",
       "50%           3.500000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic dataset Facts\n",
    "print(\"ratings shape:\", ratings.shape)\n",
    "print(\"movies shape:\", movies.shape)\n",
    "print(\"tags shape:\", tags.shape)\n",
    "\n",
    "print(\"Unique users:\", ratings[\"userId\"].nunique())\n",
    "print(\"Unique movies rated:\", ratings[\"movieId\"].nunique())\n",
    "print(\"Rating scale:\", ratings[\"rating\"].min(), \"to\", ratings[\"rating\"].max())\n",
    "\n",
    "ratings[\"rating\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 610, Movies: 9724, Ratings: 100836\n",
      "Matrix density: 0.017000\n",
      "Matrix sparsity: 0.983000\n"
     ]
    }
   ],
   "source": [
    "# Checking for data Sparsity\n",
    "n_users = ratings[\"userId\"].nunique()\n",
    "n_items = ratings[\"movieId\"].nunique()\n",
    "n_obs = len(ratings)\n",
    "\n",
    "density = n_obs / (n_users * n_items)\n",
    "sparsity = 1 - density\n",
    "\n",
    "print(f\"Users: {n_users}, Movies: {n_items}, Ratings: {n_obs}\")\n",
    "print(f\"Matrix density: {density:.6f}\")\n",
    "print(f\"Matrix sparsity: {sparsity:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Activity\n",
    "\n",
    "To better understand sparsity, we examine how many ratings each user and each movie has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratings_per_user</th>\n",
       "      <td>610.0</td>\n",
       "      <td>165.304918</td>\n",
       "      <td>269.480584</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2698.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count        mean         std   min   25%   50%    75%  \\\n",
       "ratings_per_user  610.0  165.304918  269.480584  20.0  35.0  70.5  168.0   \n",
       "\n",
       "                     max  \n",
       "ratings_per_user  2698.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratings_per_movie</th>\n",
       "      <td>9724.0</td>\n",
       "      <td>10.369807</td>\n",
       "      <td>22.401005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean        std  min  25%  50%  75%    max\n",
       "ratings_per_movie  9724.0  10.369807  22.401005  1.0  1.0  3.0  9.0  329.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ratings per user and per movie (descriptive properties)\n",
    "ratings_per_user  = ratings.groupby(\"userId\").size().rename(\"ratings_per_user\")\n",
    "ratings_per_movie = ratings.groupby(\"movieId\").size().rename(\"ratings_per_movie\")\n",
    "\n",
    "display(ratings_per_user.describe().to_frame().T)\n",
    "display(ratings_per_movie.describe().to_frame().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate models fairly, we split ratings into a training set (for model selection) and a holdout test set (for final evaluation).\n",
    "\n",
    "### Reproducibility Notes\n",
    "- Run top-to-bottom with **Restart Kernel & Run All**\n",
    "- Random seed is fixed using `RANDOM_STATE`\n",
    "- Data is loaded from `data/` relative to the notebook location\n",
    "- The holdout test set remains untouched until final evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Justification\n",
    "\n",
    "Collaborative filtering relies on user–item interactions:\n",
    "\n",
    "- **userId** identifies the user  \n",
    "- **movieId** identifies the movie  \n",
    "- **rating** is the preference signal we predict  \n",
    "\n",
    "We do not use **timestamp** in this baseline. A next step could explore time-aware recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rating distribution plot\n",
    "ratings[\"rating\"].plot(kind=\"hist\", bins=20)\n",
    "plt.title(\"MovieLens Rating Distribution\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate models fairly, I split ratings into:\n",
    "\n",
    "- Training set (80%): model fitting + cross-validation (model selection)\n",
    "\n",
    "- Holdout test set (20%): final evaluation only\n",
    "\n",
    "This prevents leakage and estimates real-world performance on unseen ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (80668, 3) test_df: (20168, 3)\n"
     ]
    }
   ],
   "source": [
    "# Splitting strategy to prevent leakage\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings[[\"userId\", \"movieId\", \"rating\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"train_df:\", train_df.shape, \"test_df:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprise dataset objects\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "train_data = Dataset.load_from_df(train_df[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "# testset must be a list of (uid, iid, true_rating)\n",
    "testset = list(test_df.itertuples(index=False, name=None))  # (userId, movieId, rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling (Iterative approach:** Baseline → kNN → Matrix Factorization)\n",
    "\n",
    "I follow an iterative modeling approach:\n",
    "\n",
    "- 1. BaselineOnly: a simple benchmark that predicts ratings using global/user/movie biases.\n",
    "\n",
    "- 2. KNNBaseline: neighborhood collaborative filtering using item-item similarity.\n",
    "\n",
    "- 3. SVD (matrix factorization): learns latent factors representing user preferences and movie characteristics.\n",
    "\n",
    "- 4. Tuned SVD: uses cross-validation to select hyperparameters for better generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "CV Results (Train Only)\n",
      "BaselineOnly  RMSE=0.8798, MAE=0.6807\n",
      "KNNBaseline   RMSE=0.8752, MAE=0.6684\n",
      "SVD (default) RMSE=0.8863, MAE=0.6841\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated model comparison on training data\n",
    "def cv_rmse_mae(algo, data, cv=3):\n",
    "    results = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=cv, verbose=False)\n",
    "    return np.mean(results[\"test_rmse\"]), np.mean(results[\"test_mae\"])\n",
    "\n",
    "baseline_algo = BaselineOnly()\n",
    "knn_algo = KNNBaseline(sim_options={\"name\": \"pearson_baseline\", \"user_based\": False})  # item-based CF\n",
    "svd_algo = SVD(random_state=42)\n",
    "\n",
    "baseline_rmse, baseline_mae = cv_rmse_mae(baseline_algo, train_data, cv=3)\n",
    "knn_rmse, knn_mae = cv_rmse_mae(knn_algo, train_data, cv=3)\n",
    "svd_rmse, svd_mae = cv_rmse_mae(svd_algo, train_data, cv=3)\n",
    "\n",
    "print(\"CV Results (Train Only)\")\n",
    "print(f\"BaselineOnly  RMSE={baseline_rmse:.4f}, MAE={baseline_mae:.4f}\")\n",
    "print(f\"KNNBaseline   RMSE={knn_rmse:.4f}, MAE={knn_mae:.4f}\")\n",
    "print(f\"SVD (default) RMSE={svd_rmse:.4f}, MAE={svd_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-by-Model Summary (Training Cross-Validation)\n",
    "\n",
    "- **BaselineOnly:** benchmark that captures overall, user, and item effects.\n",
    "- **KNNBaseline:** neighborhood collaborative filtering (item-based similarity).\n",
    "- **SVD (default):** typically more stable under sparsity than pure similarity methods.\n",
    "- **Tuned SVD:** uses cross-validation to pick settings that generalize better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model change justification: kNN vs SVD\n",
    "#### Why kNN vs Matrix Factorization?\n",
    "\n",
    "kNN collaborative filtering is intuitive and interpretable: it recommends movies similar to those a user (or similar users) liked. However, MovieLens is sparse, and similarity methods can be limited when overlap is small.\n",
    "\n",
    "Matrix factorization (SVD) learns compact latent representations of users and movies from all observed ratings, which often generalizes better in sparse settings. I therefore use kNN as a collaborative filtering baseline and SVD as the final candidate model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned SVD explanation\n",
    "#### Tuned SVD\n",
    "Tuning helps balance underfitting vs overfitting by adjusting:\n",
    "\n",
    "- Model capacity (n_factors)\n",
    "\n",
    "- Training duration (n_epochs)\n",
    "\n",
    "- Regularization (reg_all)\n",
    "\n",
    "- Learning rate (lr_all)\n",
    "\n",
    "I tune SVD using cross-validation on training data, then evaluate the selected model once on a holdout test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned SVD \n",
    "# Grid search SVD hyperparameters (train only)\n",
    "param_grid = {\n",
    "    \"n_factors\": [50, 100, 150],\n",
    "    \"n_epochs\": [20, 30],\n",
    "    \"lr_all\":   [0.002, 0.005],\n",
    "    \"reg_all\":  [0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3, joblib_verbose=0)\n",
    "gs.fit(train_data)\n",
    "\n",
    "print(\"Best RMSE score:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best params:\", gs.best_params[\"rmse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics justification + final test\n",
    "#### Evaluation\n",
    "\n",
    "**Metrics:** RMSE and MAE are appropriate because the target is a numeric rating (0.5–5.0).\n",
    "\n",
    "- RMSE penalizes large mistakes more heavily, which matters because extreme misrecommendations can reduce trust and engagement.\n",
    "\n",
    "- MAE is more interpretable as the average number of “stars” the predictions are off.\n",
    "\n",
    "**Final model selection:** I choose the final model based on cross-validated RMSE/MAE on training data and                  evaluate once on the holdout test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best tuned SVD and evaluate on holdout test\n",
    "best_params = gs.best_params[\"rmse\"]\n",
    "final_svd = SVD(**best_params, random_state=42)\n",
    "\n",
    "# Fit on full training set\n",
    "full_trainset = train_data.build_full_trainset()\n",
    "final_svd.fit(full_trainset)\n",
    "\n",
    "# Evaluate once on holdout test set\n",
    "preds = final_svd.test(testset)\n",
    "test_rmse = accuracy.rmse(preds, verbose=True)\n",
    "test_mae  = accuracy.mae(preds, verbose=True)\n",
    "\n",
    "(test_rmse, test_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Demo\n",
    "\n",
    "This section shows recommendations for (1) an existing user and (2) a new user (cold start).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You choose an existing userID\n",
    "\n",
    "# ---- YOU CHOOSE ----\n",
    "CHOSEN_USER_ID = 599  # <-- replace with any existing userId you want\n",
    "# --------------------\n",
    "\n",
    "# Quick validation:\n",
    "if CHOSEN_USER_ID not in set(ratings[\"userId\"].unique()):\n",
    "    raise ValueError(f\"userId {CHOSEN_USER_ID} not found in dataset.\")\n",
    "else:\n",
    "    print(f\"Using existing userId: {CHOSEN_USER_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what the chosen user already liked (from observed ratings)\n",
    "\n",
    "def top_rated_by_user(user_id, ratings_df, movies_df, k=5):\n",
    "    \"\"\"Return the user's top-rated movies from their rating history.\"\"\"\n",
    "    user_hist = ratings_df[ratings_df[\"userId\"] == user_id].merge(movies_df, on=\"movieId\", how=\"left\")\n",
    "    return user_hist.sort_values(\"rating\", ascending=False)[[\"userId\", \"movieId\", \"title\", \"rating\"]].head(k)\n",
    "\n",
    "print(\"User's top-rated movies (from available ratings):\")\n",
    "top_rated_by_user(CHOSEN_USER_ID, ratings, movies, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-N recommender function + existing user recommendations\n",
    "\n",
    "movie_id_to_title = dict(zip(movies[\"movieId\"], movies[\"title\"]))\n",
    "\n",
    "def top_n_recs_for_user(algo, trainset, user_id_raw, n=5):\n",
    "    \"\"\"Return Top-N recommendations for an existing user.\n",
    "\n",
    "    Steps:\n",
    "    1) Identify movies the user already rated in the training set\n",
    "    2) Predict ratings for all unseen movies\n",
    "    3) Sort by predicted rating and return the Top-N\n",
    "    \"\"\"\n",
    "    inner_uid = trainset.to_inner_uid(user_id_raw)\n",
    "\n",
    "    rated_inner_iids = {iid for (iid, _) in trainset.ur[inner_uid]}\n",
    "    all_inner_iids = set(range(trainset.n_items))\n",
    "    unseen_inner_iids = list(all_inner_iids - rated_inner_iids)\n",
    "\n",
    "    scored = []\n",
    "    for inner_iid in unseen_inner_iids:\n",
    "        raw_iid = int(trainset.to_raw_iid(inner_iid))\n",
    "        est = algo.predict(user_id_raw, raw_iid).est\n",
    "        scored.append((raw_iid, est))\n",
    "\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    top = scored[:n]\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"userId\": int(user_id_raw),\n",
    "        \"movieId\": mid,\n",
    "        \"title\": movie_id_to_title.get(mid, \"Unknown\"),\n",
    "        \"predicted_rating\": float(est)\n",
    "    } for mid, est in top])\n",
    "\n",
    "# Generate Top-5 recommendations for the chosen existing user\n",
    "top_n_recs_for_user(final_svd, full_trainset, CHOSEN_USER_ID, n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New User Simulation\n",
    "\n",
    "Collaborative filtering cannot personalize recommendations for a brand-new user with zero ratings. A standard solution is to ask the user to rate a small number of popular movies to seed the model. I simulate this by creating a new user, adding 5 initial ratings, refitting the model on training data, and generating Top-5 recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 'starter' movies for a new user to rate (popular movies create overlap)\n",
    "\n",
    "def popular_movies(ratings_df, movies_df, min_ratings=200, top_n=30):\n",
    "    \"\"\"Return popular and well-rated movies for seeding or fallback recommendations.\"\"\"\n",
    "    counts = ratings_df.groupby(\"movieId\").size().rename(\"num_ratings\")\n",
    "    means = ratings_df.groupby(\"movieId\")[\"rating\"].mean().rename(\"avg_rating\")\n",
    "    pop = pd.concat([counts, means], axis=1).reset_index()\n",
    "    pop = pop.merge(movies_df, on=\"movieId\", how=\"left\")\n",
    "    pop = pop[pop[\"num_ratings\"] >= min_ratings].sort_values(\n",
    "        [\"num_ratings\", \"avg_rating\"], ascending=False\n",
    "    )\n",
    "    return pop[[\"movieId\", \"title\", \"num_ratings\", \"avg_rating\"]].head(top_n)\n",
    "\n",
    "starter_list = popular_movies(ratings, movies, min_ratings=200, top_n=30)\n",
    "starter_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user and enter a few ratings\n",
    "\n",
    "# Create a new userId not used in the dataset\n",
    "new_user_id = int(ratings[\"userId\"].max() + 1)\n",
    "\n",
    "# Choose movieIds from starter_list and assign ratings\n",
    "# Example seed ratings (edit these to your picks)\n",
    "new_user_ratings = [\n",
    "    (new_user_id, 1, 5.0),    # Toy Story (1995) usually movieId 1 in MovieLens\n",
    "    (new_user_id, 2571, 4.5), # Matrix (1999) often 2571\n",
    "    (new_user_id, 296, 4.0),  # Pulp Fiction (1994) often 296\n",
    "    (new_user_id, 593, 4.5),  # Silence of the Lambs (1991) often 593\n",
    "    (new_user_id, 318, 5.0),  # Shawshank Redemption (1994) often 318\n",
    "]\n",
    "\n",
    "new_user_ratings_df = pd.DataFrame(new_user_ratings, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "new_user_ratings_df.merge(movies, on=\"movieId\", how=\"left\")[[\"userId\",\"movieId\",\"title\",\"rating\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train “final tuned SVD” including the new user (personalized cold-start resolution)\n",
    "# append the new ratings to the training data and refit the tuned SVD.\n",
    "# then recommend top-5\n",
    "# already have best_params from GridSearchCV earlier\n",
    "# best_params = gs.best_params[\"rmse\"]\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# IMPORTANT: add new user's ratings to TRAIN ONLY (do not touch holdout test)\n",
    "aug_train_df = pd.concat([train_df, new_user_ratings_df], ignore_index=True)\n",
    "\n",
    "aug_train_data = Dataset.load_from_df(aug_train_df[[\"userId\",\"movieId\",\"rating\"]], reader)\n",
    "aug_full_trainset = aug_train_data.build_full_trainset()\n",
    "\n",
    "final_svd_new = SVD(**best_params, random_state=42)\n",
    "final_svd_new.fit(aug_full_trainset)\n",
    "\n",
    "# Recommend for the new user\n",
    "top5_new_user = top_n_recs_for_user(final_svd_new, aug_full_trainset, new_user_id, n=5).reset_index(drop=True)\n",
    "top5_new_user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold-start fallback strategy\n",
    "Cold-start fallback (true new user with 0 ratings)\n",
    "\n",
    "If a user provides zero ratings, collaborative filtering cannot personalize. In that case, a practical fallback is to recommend movies that are both popular (many ratings) and highly rated (high average rating). This provides reasonable defaults until enough user feedback is collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback recommendations for 0-rating user\n",
    "\n",
    "fallback_recs = popular_movies(ratings, movies, min_ratings=200, top_n=10)\\\n",
    "    .sort_values([\"avg_rating\",\"num_ratings\"], ascending=False)\\\n",
    "    .head(5)[[\"movieId\",\"title\",\"num_ratings\",\"avg_rating\"]]\n",
    "\n",
    "print(\"Fallback Top-5 for a true cold-start user (0 ratings):\")\n",
    "fallback_recs.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "A compact comparison of model performance across validation and holdout test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary table (CV + Holdout)\n",
    "\n",
    "results_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"BaselineOnly\",\n",
    "        \"Validation Method\": \"3-Fold CV (train only)\",\n",
    "        \"RMSE\": baseline_rmse,\n",
    "        \"MAE\": baseline_mae\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"KNNBaseline (item-based, pearson_baseline)\",\n",
    "        \"Validation Method\": \"3-Fold CV (train only)\",\n",
    "        \"RMSE\": knn_rmse,\n",
    "        \"MAE\": knn_mae\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"SVD (default params)\",\n",
    "        \"Validation Method\": \"3-Fold CV (train only)\",\n",
    "        \"RMSE\": svd_rmse,\n",
    "        \"MAE\": svd_mae\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"SVD (tuned via GridSearchCV)\",\n",
    "        \"Validation Method\": \"3-Fold CV (train only)\",\n",
    "        \"RMSE\": gs.best_score[\"rmse\"],\n",
    "        \"MAE\": gs.best_score[\"mae\"]\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"SVD (tuned) FINAL\",\n",
    "        \"Validation Method\": \"Holdout Test (20%)\",\n",
    "        \"RMSE\": test_rmse,\n",
    "        \"MAE\": test_mae\n",
    "    }\n",
    "])\n",
    "\n",
    "# Pretty formatting\n",
    "results_summary[\"RMSE\"] = results_summary[\"RMSE\"].astype(float).round(4)\n",
    "results_summary[\"MAE\"]  = results_summary[\"MAE\"].astype(float).round(4)\n",
    "\n",
    "results_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE chart (honest scale + optional zoomed inset)\n",
    "# Goal: show differences without exaggerating them.\n",
    "\n",
    "# --- Order of models exactly as your summary table ---\n",
    "order = [\n",
    "    \"BaselineOnly\",\n",
    "    \"KNNBaseline (item-based, pearson_baseline)\",\n",
    "    \"SVD (default params)\",\n",
    "    \"SVD (tuned via GridSearchCV)\",\n",
    "    \"SVD (tuned) FINAL\"\n",
    "]\n",
    "\n",
    "plot_df = results_summary.copy()\n",
    "plot_df = plot_df[plot_df[\"Model\"].isin(order)].copy()\n",
    "plot_df[\"Model\"] = pd.Categorical(plot_df[\"Model\"], categories=order, ordered=True)\n",
    "plot_df = plot_df.sort_values(\"Model\")\n",
    "\n",
    "labels = plot_df[\"Model\"].astype(str).tolist()\n",
    "rmse = plot_df[\"RMSE\"].astype(float).values\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# ---- Zoomed range (but includes explicit bottom tick) ----\n",
    "rmse_min, rmse_max = rmse.min(), rmse.max()\n",
    "pad = 0.0008\n",
    "ymin = rmse_min - pad\n",
    "ymax = rmse_max + pad\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "bars = ax.bar(x, rmse, label=\"RMSE\", color=\"#447234\")\n",
    "\n",
    "ax.set_title(\"Model Performance (RMSE) — zoomed axis to show small differences\")\n",
    "ax.set_ylabel(\"RMSE (stars)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=20, ha=\"right\")\n",
    "\n",
    "# Set y-limits (zoomed)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# Force y-axis ticks to include the bottom starting point number\n",
    "ticks = np.linspace(ymin, ymax, 6)  # 6 ticks including bottom + top\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels([f\"{t:.4f}\" for t in ticks])\n",
    "\n",
    "# Value labels on bars (4 decimals)\n",
    "for b, v in zip(bars, rmse):\n",
    "    ax.text(b.get_x() + b.get_width()/2, v, f\"{v:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig('rmse.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Y-axis is zoomed to make small RMSE differences easier to see. Lower is better.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "#### Summary of results\n",
    "\n",
    "  I compared a baseline model, neighborhood collaborative filtering (kNN), and matrix factorization (SVD).\n",
    "\n",
    "  Hyperparameter tuning improved SVD’s cross-validated performance and produced strong holdout test results (RMSE/MAE).\n",
    "\n",
    "  The system generates Top-5 recommendations for existing users and can handle new users via seeded ratings or popularity-based   fallback.\n",
    "  \n",
    "##### On the holdout test set, the tuned SVD achieved RMSE ≈ 0.88, meaning predictions are typically within about ~0.9 stars of the   true rating.\n",
    "\n",
    "#### Business implications\n",
    "\n",
    "  Personalized recommendations can reduce choice overload and improve engagement and retention.\n",
    "\n",
    "  A cold-start strategy is necessary for new users and new content.\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "  Sparse rating matrix limits personalization for low-activity users\n",
    "\n",
    "  No user demographics or rich item metadata\n",
    "\n",
    "  Offline RMSE/MAE does not fully capture business KPIs (e.g., click-through, watch-time)\n",
    "\n",
    "#### Next steps\n",
    "\n",
    "Add a simple hybrid (content + CF) using genres/tags for cold-start\n",
    "\n",
    "Evaluate with ranking metrics (Precision@K / Recall@K) and online A/B testing\n",
    "\n",
    "Incorporate implicit feedback (clicks, watch-time) for production use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
